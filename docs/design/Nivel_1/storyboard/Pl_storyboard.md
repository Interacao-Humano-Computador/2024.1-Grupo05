## Introdução

Seguindo o processo de deisgn de Mayhew (1999), escolhido para o projeto, após concluídas as etapas de estabelecimento de requisitos é iniciado o desenvolvimento de design. Torna-se necessário, para dar continuidade ao papel do avaliador, a elaboração de protótipos dos cenários estabelecidos no projeto, tornando possível uma visualização mais direta e a verificação da ideia estabelecida pelo avaliador pelos próprios usuários do site avaliado.

## Objetivo

Neste documento será apresentado o planejamento de avaliação dos protótipos, além de um planejamento referente ao relato dos resultados de tais avaliações. É esperado que, após realizadas as devidas verificações, o projeto possa prosseguir ao nível 2 de design estabelecido pelo processo de design anteriormente mencionado.

## Metodologia

Será utilizada, para o propósito desta avaliação, uma abordagem planejada com base no framework DECIDE, proposto por Preece et al. (2002). Também será utilizado a interpretação de Barbosa et al. (2010) para o estabelecimento e acompanhamento das instruções do framework mencionado, sendo separado cada etapa pelas letras que nomeiam o mesmo.

### Determinar o objetivo (D)

- Apropriação da tecnologia pelos usuários (I)
- Problemas na interação e na interface (II)

### Explorar as perguntas da avaliação (E)

Ao analisar o objetivo I temos as seguintes perguntas principais:

    - Por que os usuários não incorporaram o sistema no seu cotidiano?
    - Quais objetivos dos usuários podem ser alcançados através do sistema? Quais não podem? Quais necessidades e
desejos foram ou não atendidos?
    - Como o sistema interativo afeta o modo de as pessoas se comunicarem e relacionarem?

Já referente ao objetivo II:

    - Que parte da interface e da interação o deixa insatisfeito?
    - Ele entende o que significa e para que serve cada elemento de interface?
    - Ele vai entender o que deve fazer em seguida?
    - Quais barreiras o usuário encontra para atingir seus objetivos?

### Escolher o(s) método(s) de avaliação (C)

Dada uma divisão de objetivos principais a serem avaliados, o grupo irá realizar a avaliação de cada objetivo por métodos distintos, de forma que o primeiro objetivo, referente à apropriação de tecnologia (I), será trabalhado pelo método de investigação pelo intermédio de entrevistas com usuários do site. A respeito do objetivo referente aos problemas na interação e interface (II), será trabalhado pelo uso do método de inspeção con intermédio de avaliações heurísticas, baseadas nas propostas de Nielsen (1994), com enfoque nas seguintes heurísticas: visibilidade do estado do sistema, correspondência entre o sistema e o mundo real, prevenção de erros e consistência e padronização.

### Identificar as questões práticas da avaliação (I)

Para o objetivo I, será necessário o contato com indivíduos do município de Lagoa da Prata que, por meio de entrevista, consigam julgar os protópipos realizados pela equipe e também fornecer feedback referente ao seu uso da plataforma com as funcionalidades retratadas. Baseado na proposta de Dumas & Redish (1999), serão entrevistados cinco usuários. Cada entrevista será realizada por um membro do grupo de IHC de modo online. As entrevistas serão realizadas via Microsoft Teams, plataforma gratuita para os estudantes da Universidade de Brasília que permite chamadas de voz ou vídeo e oferece gravações.

Já para a análise do objetivo II, devido ao método de inspeção, será necessário a verificação dos horários de cada membro encarregado por cada avaliação e de suas ferramentas em estado funcional, gerando um baixo custo em geral, além de simplicidade ao não envolver pessoas externas. Cada avaliador se responsabilizará por compreender o perfil que utilizará quando realizar a avaliação, listar os problemas encontrados com dados de local, gravidade, justificativa e recomendações de solução.

### Decidir como lidar com as questões éticas (D)

Será necessário por parte da equipe, referente em especial ao objetivo I, elaborar o TCLE (Termo de Consentimento Livre e Esclarecido) e um planejamento individualizado para a entrevista que deverá ser gravada quando possível, com a devida autorização de ambas partes envolvidas. Estes aspectos deverão estar em conformidade com a resolução nº466/2012, de modo a proteger e promover a integridade física e mental do usuário envolvido, além dos pesquisadores.

### Avaliar e administrar os dados da avaliação (E)

Para o recolhimento de dados da entrevista, o avaliador responsável deverá, inicialmente, registrar os dados do entrevistado de nome, idade, profissão. Em seguida, irá recolher as respostas do usuário a respeito da prototipação apresentada e seus comentários. Caberá ao entrevistador e ao revisor da equipe a interpretação do dado para estabelecer o feedback subjetivo em um conceito geral que possa ser verificado por outros stakeholders e, possivelmente, os desenvolvedores do site. Os dados deverão ser registrados conforme níveis de relevância no contexto de IHC e do usuário, com o site avaliado em pequena, mediana e alta, tendo como critério inicial de distinção, o quanto o feedback do usuário lhe promove um bom incentivo à utilização do site e da funcionalidade apresentada, além de sua recomendação a outras pessoas para a utilização da mesma funcionalidade.

Já para os dados provenientes da avaliação heurística, será seguido o modelo proposto por Barbosa (2021) quando se refere ao registro dos métodos de Nielsen (1994. O modelo é composto pelos itens: objetivos da avaliação, escopo da avaliação, descrição do método de heurística, conjunto de diretrizes, número e perfil dos avaliadores e  listagem de problemas encontrados (sendo que cada problema deve conter, por sua vez, local, descrição, diretriz violada, severidade e sugestões de solução). Os resultados individuais de cada avaliador serão levados ao grupo como um todo e analisados novamente, realizando uma revisão dos problemas encontrados e conformidade com o planejamento, assim como se as soluções propostas estão de acordo com a realidade.

## Histórico de Revisão

|    Data    | Versão |                Descrição                 |                                         Autor(es)                                          | Data de revisão |                 Revisor(es)                  |
| :--------: | :----: | :--------------------------------------: | :----------------------------------------------------------------------------------------: | :-------------: | :------------------------------------------: |
| 22/05/2024 | `1.0`  |  Elaboração inicial do documento   |      [Lucas Meireles](https://github.com/Katuner) |  22/05/2024 | [Lucas Heler](https://github.com/akaeboshi) |

## Referencial Bibliográfico

> [1] Mayhew, Deborah J. (1999). The Usability Engineering Lifecycle: A Practitioner’s Handbook for User Interface Design. Morgan Kaufmann, 1st edition edition.

> [2] Preece, Jennifer, Rogers, Yvonne, e Sharp, Helen (2002). Interaction Design: Beyond Human-Computer Interaction. John Wiley & Sons.

> [3] Barbosa, S. D. J.; Silva, B. S. da; Silveira, M. S.; Gasparini, I.; Darin, T.; Barbosa, G. D. J. (2021) Interação Humano-Computador e Experiência do usuário. Autopublicação. ISBN: 978-65-00-19677-1.

> [4] Nielsen, Jakob (1994). Usability Engineering. Morgan Kaufmann Publishers Inc., San Francisco, CA, USA.

> [5] BRASIL. Resolução nº 466, de 12 de dezembro de 2012, que trata de pesquisas em seres humanos e atualiza a resolução 196. Brasília, DF: Diário Oficial da União, 2013. Disponível em: <https://conselho.saude.gov.br/resolucoes/2012/Reso466.pdf> Acesso em: 06/05/2024.

> [6] Dumas, Joseph S. e Redish, Janice C. (1999). A Practical Guide to Usability Testing. Intellect Books, GBR, 1st edition.

