## Introdução
Conforme apontam Simone Barbosa e Bruno Diniz<a id=anchor_1 href="#REF1"><sup>1</sup></a>: A avaliação do produto final possibilita entregar um produto com
uma garantia maior de qualidade. Sob esse viés esse artefato tem como objetivo fazer o planejamento da avaliação do protótipo de alta fidelidade, realizando entrevista com usuários reais do produto, tendo como referência o [perfil do usuario](../../requisitos1/perfil-do-usuario.md) previamente estabelecido.

## Metodologia
Para realizar esse planejamento foi utilizado o framework DECIDE proposto para orientar o planejamento, execução e análise de uma avaliação de Interação Humano Computador.<a id=anchor_2 href="#REF2"><sup>2</sup></a> A tabela 1 a seguir apresenta o siginificado de cada letra do framework assim como o objetivo de cada tópico.

<center>
**Tabela 1** - Letras e significados DECIDE

| Letra | Significado                                          |
| ----- | ---------------------------------------------------- |
| D     | Determinar os objetivos gerais da avaliação          |
| E     | Explorar perguntas a serem feitas na avaliação       |
| C     | Escolher os métodos de avaliação                     |
| I     | Identificar e administrar as questões práticas       |
| D     | Decidir como lidar com as questões éticas            |
| E     | Avaliar, interpretar e apresentar os dados           |

*Fonte: [Dourado, Pedro Lucas.](https://github.com/lucasdray) 2024.*
</center>

## Planejamento


### D - Determinar os objetivos
O objetivo da avaliação é testar a usabilidade, funcionalidade e interface do protótipo de alta fidelidade obtendo um feedback de usuários reais para que seja possível melhorar o protótipo e assemelhando de forma mais precisa à versão final do produto.

### E - Explorar perguntas
Para alcançar o objetivo foram preparadas perguntas que serão respondidas na avaliação, sendo elas divididas em 4 tópicos e baseadas no Captítulo 11 da literatura de Barbosa e Silva (2011, p.266)<a id="REF1" href="#anchor_1">1.</a> e podem ser vistos na tabela 02 abaixo:

| Objetivo                                       | Perguntas                                                                                                                                                                                                                                             |
| ---------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Analisar a apropriação da tecnologia           | -  Os objetivos definidos foram alcançados? <br> - O que é possível modificar no sistema para torná-lo mais interativo?                                                                                                                               |
| Verificar a conformidade com um padrão         | - O sistema está de acordo com os padrões de acessibilidade do W3C?                                                                                                                                                                                   |
| Identificar problemas na interação e interface | - O usuário consegue operar o sistema? <br>  O usuário atinge seu objetivo? Após cometer quantos erros? Quais barreiras o usuário encontra para atingir seus objetivos? <br> Que parte da interface e da interação deixa o usuário insatisfeito? <br> |



### C - Escolher os métodos
Para a avaliação será usado o método de observação utilizando o teste de usabilidade que visa a avaliar a usabilidade de um sistema interativo a partir de experiências de
uso dos seus usuários-alvo (Rubin, 1994; Rubin e Chisnell, 2008).<a id=anchor_3 href="#REF3"><sup>3</sup></a> Como compreendido na literatura de Barbosa e Silva <a id=anchor_1 href="#REF1"><sup>1</sup></a> os teste de usabilidade irão seguir as [metas de usabilidade](../../requisitos2/metas-usabilidade.md) anteriormente definidas no projeto, sendo avaliado se o sistema a às atingiu. A escolha do método se dá pela ampla possibilidade de coleta de informações e recepção de feedbacks, além de permitir fazer perguntas para os usuários reais sobre os objetivos a serem alcançados.

### I - Identificar as questões práticas
Para selecionar os participantes da avaliação, usaremos o critério definido no Perfil de Usuário. Seguiremos a recomendação de Dumas e Redish<a id=anchor_4 href="#REF4"><sup>4</sup></a> , que afirmam que uma avaliação de IHC deve envolver de cinco a doze usuários, sendo escolhido apenas cinco por conta de custos e gestão de tempo, já que, são suficientes para detectar a 85% dos problemas, como relata Nielsen<a id=anchor_5 href="#REF5"><sup>5</sup></a> .



## Referências

> <a id="REF1" href="#anchor_1">1.</a> Barbosa, S. D. J., & Diniz, B. (2010). Interação Humano-Computador. Elsevier Brasil.
> <a id="REF2" href="#anchor_2">2.</a> Preece, Jennifer, Rogers, Yvonne, e Sharp, Helen (2002). Interaction Design: Beyond Human-Computer
Interaction. John Wiley & Sons.
> <a id="REF3" href="#anchor_3">3.</a>Rubin, Jeffrey (1994). Handbook of Usability Testing: How to Plan, Design, and Conduct Effective Tests.
John Wiley & Sons, Inc., USA, 1st edition.
> <a id="REF4" href="#anchor_4">4.</a>Dumas, J. S., & Redish, J. C. (1999). A practical guide to usability testing. Intellect Books.
> <a id="REF5" href="#anchor_5">5.</a>Nielsen, J. (1994). Usability Engineering at a Discount. In CHI'94 Conference Companion on Human Factors in Computing Systems (pp. 291-292).

## Histórico de Versões
|    Data    | Versão |            Descrição            |                  Autor(es)                  | Data de revisão | Revisor(es) |
| :--------: | :----: | :-----------------------------: | :-----------------------------------------: | :-------------: | :---------: |
| 16/06/2024 | `1.0`  | Elaboração inicial do documento | [Pedro Lucas](https://github.com/lucasdray) |                 |             |
